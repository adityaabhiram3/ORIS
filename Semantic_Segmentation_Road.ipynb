{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "segUnet_4_diff_kern_init.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YXDtY0r3WPXO",
        "outputId": "f88c23dc-3b5e-456b-9bf5-c63a8e119205"
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "!pip install tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow-gpu in /usr/local/lib/python3.7/dist-packages (2.4.1)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.2)\n",
            "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12.1)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.7.4.3)\n",
            "Requirement already satisfied: h5py~=2.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.10.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.2.0)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.12.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.3.0)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.12)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.36.2)\n",
            "Requirement already satisfied: grpcio~=1.32.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.32.0)\n",
            "Requirement already satisfied: gast==0.3.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (0.3.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.5.0,>=2.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.0)\n",
            "Requirement already satisfied: tensorboard~=2.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (2.4.1)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (3.12.4)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.6.3)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow-gpu) (1.15.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.28.0)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (3.3.4)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (54.2.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (0.4.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (1.0.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.4->tensorflow-gpu) (2.23.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (4.2.1)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.8.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (1.3.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.4->tensorflow-gpu) (1.24.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2,>=1.6.3->tensorboard~=2.4->tensorflow-gpu) (0.4.8)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard~=2.4->tensorflow-gpu) (3.4.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.4->tensorflow-gpu) (3.1.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Tl-rUhQYifc",
        "outputId": "f856c1ef-d670-422c-afad-0c08ebe927b5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFkv4-fbYmFa",
        "outputId": "fe248d05-2fb4-4d06-beaa-875eaaa9e7c2"
      },
      "source": [
        "import scipy.misc\n",
        "import cv2\n",
        "from imutils import paths\n",
        "from tqdm import tqdm\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import os\n",
        "import random\n",
        "import tensorflow as tf\n",
        "import datetime\n",
        "from glob import glob\n",
        "import IPython.display as display\n",
        "from IPython.display import clear_output\n",
        "import math\n",
        "import time\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import csv\n",
        "from tensorflow.keras.layers import *\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "print(f'Tensorflow ver. {tf.__version__}')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensorflow ver. 2.4.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzYpqEFB0Al-"
      },
      "source": [
        "#delete files from trash in drive\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "my_drive = GoogleDrive(gauth)\n",
        "\n",
        "def delTrash() :\n",
        "    for file in my_drive.ListFile({'q': \"trashed = true\"}).GetList():\n",
        "        #print(f'the file \"{a_file['title']}\", is about to get deleted permanently.')\n",
        "        file.Delete()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-4inB1pYvge"
      },
      "source": [
        "SEED = random.choice([32, 50, 100])\n",
        "os.chdir(\"drive/My Drive/segUnet3\")\n",
        "dataset_path = 'idd20k_lite/'\n",
        "img_val = dataset_path + 'leftImg8bit/val/'\n",
        "seg_val = dataset_path + 'gtFine/val/'\n",
        "img_train = dataset_path + 'leftImg8bit/train/'\n",
        "seg_train = dataset_path + 'gtFine/train/'\n",
        "(IMG_HEIGHT,IMG_WIDTH) = (128,256)\n",
        "N_CHANNELS = 3\n",
        "N_CLASSES = 8 \n",
        "TRAIN_SIZE= len(glob(img_train+'*/*_image.jpg'))\n",
        "VAL_SIZE = len(glob(img_val+'*/*_image.jpg'))\n",
        "BATCH_SIZE = 32\n",
        "BUFFER_SIZE = 1500"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-C5xHa4Yashv"
      },
      "source": [
        "# Load Dataset from folder here\n",
        "def parse_image(img_path):\n",
        "    image = tf.io.read_file(img_path)\n",
        "    image = tf.image.decode_jpeg(image, channels=3)\n",
        "    mask_path = tf.strings.regex_replace(img_path, \"leftImg8bit\", \"gtFine\")\n",
        "    mask_path = tf.strings.regex_replace(mask_path, \"_image.jpg\", \"_label.png\")\n",
        "    mask = tf.io.read_file(mask_path)\n",
        "    mask = tf.image.decode_png(mask, channels=1)\n",
        "    mask = tf.where(mask==255, np.dtype('uint8').type(7), mask)\n",
        "    return {'image': image, 'mask': mask}\n",
        "def load_train(datapoint):\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_HEIGHT, IMG_WIDTH))\n",
        "    input_mask = tf.image.resize(datapoint['mask'], (IMG_HEIGHT, IMG_WIDTH))\n",
        "    if tf.random.uniform(()) > 0.5:\n",
        "        input_image = tf.image.flip_left_right(input_image)\n",
        "        input_mask = tf.image.flip_left_right(input_mask)\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "def load_test(datapoint):\n",
        "    input_image = tf.image.resize(datapoint['image'], (IMG_HEIGHT, IMG_WIDTH))\n",
        "    input_mask = tf.image.resize(datapoint['mask'], (IMG_HEIGHT, IMG_WIDTH))\n",
        "    input_image = tf.cast(input_image, tf.float32) / 255.0\n",
        "    return input_image, input_mask\n",
        "\n",
        "train_dataset_list = tf.data.Dataset.list_files(img_train+'*/*_image.jpg', seed=SEED)\n",
        "train_dataset = train_dataset_list.map(parse_image)\n",
        "val_dataset_list = tf.data.Dataset.list_files(img_val+'*/*_image.jpg', seed=SEED)\n",
        "val_dataset = val_dataset_list.map(parse_image)\n",
        "dataset = {\"train\": train_dataset, \"val\": val_dataset}\n",
        "def prepareDataset(dataset) :\n",
        "    dataset['train'] = dataset['train'].map(load_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset['train'] = dataset['train'].shuffle(buffer_size=BUFFER_SIZE, seed=SEED)\n",
        "    dataset['train'] = dataset['train'].repeat()\n",
        "    dataset['train'] = dataset['train'].batch(BATCH_SIZE)\n",
        "    dataset['train'] = dataset['train'].prefetch(buffer_size=AUTOTUNE)\n",
        "    dataset['val'] = dataset['val'].map(load_test)\n",
        "    dataset['val'] = dataset['val'].repeat()\n",
        "    dataset['val'] = dataset['val'].batch(BATCH_SIZE)\n",
        "    dataset['val'] = dataset['val'].prefetch(buffer_size=AUTOTUNE)\n",
        "prepareDataset(dataset)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LxBGk5tdnKNb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 652
        },
        "outputId": "7d0ae2fb-f7bc-489f-98e4-184311b2f380"
      },
      "source": [
        "class Downsampling(tf.keras.Model):\n",
        "    def model(self):\n",
        "        if self.layer == 1:\n",
        "            x = Input(shape=(128,128,3))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 2:\n",
        "            x = Input(shape=(128,128,64))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 3:\n",
        "            x = Input(shape=(64,64,128))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 4:\n",
        "            x = Input(shape=(32,32, 256))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 5:\n",
        "            x = Input(shape=(16, 16, 512))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "\n",
        "    def __init__(self, filter_size, layer, initializer= None):\n",
        "        super(Downsampling, self).__init__()\n",
        "        self.layer = layer\n",
        "        self.filter_size = filter_size\n",
        "        self.initializer = initializer\n",
        "        self.conv1 = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)\n",
        "        self.conv2 = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)\n",
        "\n",
        "    def call(self,inputs):\n",
        "        if(self.layer==1):\n",
        "            x = self.conv1(inputs)\n",
        "            x = self.conv2(x)\n",
        "            return x\n",
        "        x = MaxPooling2D(pool_size=(2,2))(inputs)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        return x\n",
        "\n",
        "class Upsampling(tf.keras.Model):\n",
        "    def model(self):\n",
        "        if self.layer == 1:\n",
        "            x = Input(shape=(8, 8, 1024))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 2:\n",
        "            x = Input(shape=(16, 16, 512))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 3:\n",
        "            x = Input(shape=(32, 32, 256))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 4:\n",
        "            x = Input(shape=(64, 64, 128))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        elif self.layer == 5:\n",
        "            x = Input(shape=(128, 128, 2))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "    def __init__(self, filter_size, layer, initializer= None):\n",
        "        super(Upsampling, self).__init__()\n",
        "        self.filter_size = filter_size\n",
        "        self.layer = layer\n",
        "        self.initializer = initializer\n",
        "        self.conv1 = Convolution2D(self.filter_size, 2, activation = 'relu', padding='same', kernel_initializer=self.initializer)\n",
        "        self.conv2 = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)\n",
        "        self.conv3 = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)\n",
        "        self.conv4 = Convolution2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer=self.initializer)\n",
        "    \n",
        "    def call(self,inputs,upsampling_layer):\n",
        "        x = self.conv1(UpSampling2D(size=(2,2))(inputs))\n",
        "        merged = concatenate([upsampling_layer,x], axis=3)\n",
        "        x = self.conv2(merged)\n",
        "        x = self.conv3(x)\n",
        "        if(self.layer==4):\n",
        "            x = self.conv4(x)\n",
        "        return x\n",
        "\n",
        "class segUnetModel(tf.keras.Model):\n",
        "    def model(self, all = 0):\n",
        "        if all == 0:\n",
        "            x = Input(shape=(128,128,3))\n",
        "            return tf.keras.Model(inputs=[x], outputs=self.call(x))\n",
        "        else:\n",
        "            print(self.layer1.model())\n",
        "            print(self.layer2.model())\n",
        "            print(self.layer3.model())\n",
        "            print(self.layer4.model())\n",
        "            print(self.layer5.model())\n",
        "            print(self.layer6.model())\n",
        "            print(self.layer7.model())\n",
        "            print(self.layer8.model())\n",
        "            print(self.layer9.model())\n",
        "\n",
        "    def __init__(self, output_channels, initializer = None):\n",
        "        super(segUnetModel, self).__init__()\n",
        "        self.output_channels = output_channels\n",
        "        self.layer1 = Downsampling(64,1)\n",
        "        self.layer2 = Downsampling(128,2)\n",
        "        self.layer3 = Downsampling(256,3)\n",
        "        self.layer4 = Downsampling(512,4)\n",
        "        self.layer5 = Downsampling(1024,5)\n",
        "        self.layer6 = Upsampling(512,1)\n",
        "        self.layer7 = Upsampling(256,2)\n",
        "        self.layer8 = Upsampling(128,3)\n",
        "        self.layer9 = Upsampling(64,4)\n",
        "        self.output_layer = Convolution2D(self.output_channels, 1, activation='softmax')\n",
        "    def call(self,inputs):\n",
        "        conv1 = self.layer1(inputs)\n",
        "        conv2 = self.layer2(conv1)\n",
        "        conv3 = self.layer3(conv2)\n",
        "        conv4 = self.layer4(conv3)\n",
        "        conv5 = self.layer5(conv4)\n",
        "        convtr1 = self.layer6(conv5,conv4)\n",
        "        convtr2 = self.layer7(convtr1,conv3)\n",
        "        convtr3 = self.layer8(convtr2,conv2)\n",
        "        convtr4 = self.layer9(convtr3,conv1)\n",
        "        output = self.output_layer(convtr4)\n",
        "        return output\n",
        "\n",
        "model = segUnetModel(N_CLASSES)\n",
        "model.model().summary()"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_16\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_20 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "downsampling_230 (Downsampling) (None, 128, 128, 64) 38720       input_20[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "downsampling_231 (Downsampling) (None, 64, 64, 128)  221440      downsampling_230[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "downsampling_232 (Downsampling) (None, 32, 32, 256)  885248      downsampling_231[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "downsampling_233 (Downsampling) (None, 16, 16, 512)  3539968     downsampling_232[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "downsampling_234 (Downsampling) (None, 8, 8, 1024)   14157824    downsampling_233[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "upsampling_184 (Upsampling)     (None, 16, 16, 512)  9176576     downsampling_234[0][0]           \n",
            "                                                                 downsampling_233[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "upsampling_185 (Upsampling)     (None, 32, 32, 256)  2294528     upsampling_184[0][0]             \n",
            "                                                                 downsampling_232[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "upsampling_186 (Upsampling)     (None, 64, 64, 128)  573824      upsampling_185[0][0]             \n",
            "                                                                 downsampling_231[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "upsampling_187 (Upsampling)     (None, 128, 128, 2)  144706      upsampling_186[0][0]             \n",
            "                                                                 downsampling_230[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1268 (Conv2D)            (None, 128, 128, 8)  24          upsampling_187[0][0]             \n",
            "==================================================================================================\n",
            "Total params: 31,032,858\n",
            "Trainable params: 31,032,858\n",
            "Non-trainable params: 0\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nclass Downsampling(tf.keras.Model):\\n    def __init__(self, filter_size, layer, initializer= None):\\n        super(Downsampling, self).__init__()\\n        self.layer = layer\\n        self.filter_size = filter_size\\n        self.initializer = initializer\\n\\n    def call(self,inputs):\\n        if(self.layer==1):\\n            x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(inputs)\\n            x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(x)\\n            return x\\n        x =  MaxPooling2D(pool_size=(2,2))(inputs)\\n        x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(x)\\n        x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(x)\\n        return x\\n    def model(self):\\n        if self.layer == 1:\\n            x = Input(shape=(128,128,3))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 2:\\n            x = Input(shape=(128,128,64))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 3:\\n            x = Input(shape=(64,64,128))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 4:\\n            x = Input(shape=(32,32, 256))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 5:\\n            x = Input(shape=(16, 16, 512))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n  \\nclass Upsampling(tf.keras.Model):\\n    \\n    def __init__(self, filter_size, block_number, initializer= None):\\n        super(Upsampling, self).__init__()\\n        self.filter_size = filter_size\\n        self.block_number = block_number\\n        self.initializer = initializer\\n    def call(self,inputs,upsampling_layer):\\n        x = Convolution2D(self.filter_size, 2, activation = 'relu', padding='same', kernel_initializer=self.initializer)(UpSampling2D(size=(2,2))(inputs))\\n        #x = Convolution2D(self.filter_size, 2, activation = 'relu', padding='same', kernel_initializer=self.initializer)(UpSampling2D(size=(2,2))(inputs)))\\n        merged = concatenate([upsampling_layer,x], axis=3)\\n        x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(merged)\\n        x = Convolution2D(self.filter_size, 3, activation = 'relu', padding='same', kernel_initializer=self.initializer)(x)\\n        if(self.block_number==4):\\n            x = Convolution2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = self.initializer)(x)\\n        return x\\n    def model(self):\\n        if self.layer == 1:\\n            x = Input(shape=(8, 8, 1024))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 2:\\n            x = Input(shape=(16, 16, 512))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 3:\\n            x = Input(shape=(32, 32, 256))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 4:\\n            x = Input(shape=(64, 64, 128))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n        elif self.layer == 5:\\n            x = Input(shape=(128, 128, 2))\\n            return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n \\nclass segUnetModel(tf.keras.Model):\\n    \\n    def __init__(self, output_channels, initializer = None):\\n        super(segUnetModel, self).__init__()\\n        self.output_channels = output_channels\\n        self.downsampling_1 = Downsampling(64,1)\\n        self.downsampling_2 = Downsampling(128,2)\\n        self.downsampling_3 = Downsampling(256,3)\\n        self.downsampling_4 = Downsampling(512,4)\\n        self.downsampling_5 = Downsampling(1024,5)\\n        self.upsampling_1 = Upsampling(512,1)\\n        self.upsampling_2 = Upsampling(256,2)\\n        self.upsampling_3 = Upsampling(128,3)\\n        self.upsampling_4 = Upsampling(64,4)\\n        self.output_layer = Convolution2D(self.output_channels, 1, activation='softmax')\\n    \\n    def model(self):\\n        x = Input(shape=(128,128,3))\\n        return tf.keras.Model(inputs=[x], outputs=self.call(x))\\n\\n    def call(self,inputs):\\n        # Convolutinal layers on inputs\\n        conv_enc_1 = self.downsampling_1(inputs)\\n        conv_enc_2 = self.downsampling_2(conv_enc_1)\\n        conv_enc_3 = self.downsampling_3(conv_enc_2)\\n        conv_enc_4 = self.downsampling_4(conv_enc_3)\\n        conv_enc_5 = self.downsampling_5(conv_enc_4)\\n        # Upsampling in keras increases the size of input\\n        conv_dec_1 = self.upsampling_1(conv_enc_5,conv_enc_4)\\n        conv_dec_2 = self.upsampling_2(conv_dec_1,conv_enc_3)\\n        conv_dec_3 = self.upsampling_3(conv_dec_2,conv_enc_2)\\n        conv_dec_4 = self.upsampling_4(conv_dec_3,conv_enc_1)\\n        output = self.output_layer(conv_dec_4)\\n        return output\\n\\nmodel = segUnetModel(8)\\nmodel.model().summary()\\n\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_ysJkFmniCt"
      },
      "source": [
        "# define loss and other metrics\n",
        "loss_func = tf.keras.losses.SparseCategoricalCrossentropy()\n",
        "optimizer = tf.keras.optimizers.Adam()\n",
        "ckpt = tf.train.Checkpoint(step=tf.Variable(1), optimizer=optimizer, net=model)\n",
        "manager = tf.train.CheckpointManager(ckpt, 'tf_ckpts/', max_to_keep=3)\n",
        "train_loss = tf.keras.metrics.Mean('train_loss', dtype=tf.float32)\n",
        "train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('train_accuracy')\n",
        "test_loss = tf.keras.metrics.Mean('test_loss', dtype=tf.float32)\n",
        "test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy('test_accuracy')\n",
        "\n",
        "# function to calculate loss every step and checkpoint\n",
        "@tf.function\n",
        "def train_step(model, optimizer, x_train, y_train):\n",
        "    with tf.GradientTape() as tape:\n",
        "        predictions = model(x_train, training=True)\n",
        "        loss = loss_func(y_train, predictions)\n",
        "    grads = tape.gradient(loss, model.trainable_variables)\n",
        "    optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "    train_loss(loss)\n",
        "    train_accuracy(y_train, predictions)\n",
        "\n",
        "@tf.function\n",
        "def test_step(model, x_test, y_test):\n",
        "    predictions = model(x_test)\n",
        "    loss = loss_func(y_test, predictions)\n",
        "    test_loss(loss)\n",
        "    test_accuracy(y_test, predictions)\n",
        "    return predictions\n",
        "\n",
        "def train_and_checkpoint(model, manager, dataset, epoch):\n",
        "    ckpt.restore(manager.latest_checkpoint)\n",
        "    if manager.latest_checkpoint:\n",
        "        print(\"Restored from {}\".format(manager.latest_checkpoint))\n",
        "    else:\n",
        "        print(\"Initializing from scratch.\")\n",
        "    for (x_train, y_train) in dataset['train'].take(math.ceil(TRAIN_SIZE/BATCH_SIZE)):\n",
        "        train_step(model, optimizer, x_train, y_train)\n",
        "        return\n",
        "    ckpt.step.assign_add(1)\n",
        "    save_path = manager.save()\n",
        "    print(\"Saved checkpoint for epoch {}: {}\".format(epoch, save_path))\n",
        "    \n",
        "\n",
        "train_log_dir = 'logs/gradient_tape/train'\n",
        "test_log_dir = 'logs/gradient_tape/test'\n",
        "train_summary_writer = tf.summary.create_file_writer(train_log_dir)\n",
        "test_summary_writer = tf.summary.create_file_writer(test_log_dir)"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PbsSGS9IxhRq"
      },
      "source": [
        "# function to train the model\n",
        "# give input file name where model accuracy will be stored every epoch\n",
        "highest_accuracy = 0\n",
        "noEpochs = 100\n",
        "startEpoch = 0\n",
        "fields = ['Epoch', 'Loss', 'Acc', 'Val Loss', 'Val Acc'] \n",
        "filename = input(\"Enter File Name without type : \") + \".txt\"\n",
        "paramsFile = open(filename, \"w+\")\n",
        "paramsFile.write(','.join(fields))\n",
        "paramsFile.write(\"\\n\")\n",
        "paramsFile.close()\n",
        "for epoch in range(startEpoch, startEpoch + noEpochs):\n",
        "\n",
        "    print(\"Epoch \",epoch+1)\n",
        "    delTrash()\n",
        "    start = time.time()\n",
        "    \n",
        "    train_and_checkpoint(model, manager, dataset, epoch+1)\n",
        "    break\n",
        "    with train_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', train_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', train_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    for (x_test, y_test) in dataset['val'].take(math.ceil(VAL_SIZE/BATCH_SIZE)):\n",
        "        pred = test_step(model, x_test, y_test)\n",
        "    \n",
        "    with test_summary_writer.as_default():\n",
        "        tf.summary.scalar('loss', test_loss.result(), step=ckpt.step.numpy())\n",
        "        tf.summary.scalar('accuracy', test_accuracy.result(), step=ckpt.step.numpy())\n",
        "    \n",
        "    #print(\"Time taken \",time.time()-start)\n",
        "    \n",
        "    template = 'Epoch {}, Loss: {:.3f}, Accuracy: {:.3f}, Val Loss: {:.3f}, Val Accuracy: {:.3f}'\n",
        "    otemp = '{}, {:.3f}, {:.3f}, {:.3f}, {:.3f}'\n",
        "    print (template.format(epoch+1,\n",
        "                            train_loss.result(), \n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(), \n",
        "                            test_accuracy.result()*100))\n",
        "    text = otemp.format(epoch+1,\n",
        "                            train_loss.result(), \n",
        "                            train_accuracy.result()*100,\n",
        "                            test_loss.result(), \n",
        "                            test_accuracy.result()*100)\n",
        "    paramsFile = open(filename, \"a\")\n",
        "    paramsFile.write(text+\"\\n\") \n",
        "    paramsFile.close()\n",
        "    if(test_accuracy.result().numpy()*100>highest_accuracy):\n",
        "        print(\"Validation accuracy increased from {:.3f} to {:.3f}. Saving model weights.\".format(highest_accuracy,test_accuracy.result().numpy()*100))\n",
        "        highest_accuracy = test_accuracy.result().numpy()*100\n",
        "        model.save_weights('unet_weights-epoch-{}.hdf5'.format(epoch+1))\n",
        "\n",
        "    print('_'*80)\n",
        "    \n",
        "    # Reset metrics after every epoch\n",
        "    train_loss.reset_states()\n",
        "    test_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "    test_accuracy.reset_states()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xFNMe529YByW",
        "outputId": "4521de75-f2f3-4623-bb68-ef592b71625c"
      },
      "source": [
        "model = segUnetModel(8)\n",
        "model.build(input_shape=(None,128,128,3))\n",
        "model.summary()\n",
        "model.load_weights('Model3/unet_weights-epoch-87.hdf5')"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"seg_unet_model_48\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "downsampling_240 (Downsampli multiple                  38720     \n",
            "_________________________________________________________________\n",
            "downsampling_241 (Downsampli multiple                  221440    \n",
            "_________________________________________________________________\n",
            "downsampling_242 (Downsampli multiple                  885248    \n",
            "_________________________________________________________________\n",
            "downsampling_243 (Downsampli multiple                  3539968   \n",
            "_________________________________________________________________\n",
            "downsampling_244 (Downsampli multiple                  14157824  \n",
            "_________________________________________________________________\n",
            "upsampling_192 (Upsampling)  multiple                  9176576   \n",
            "_________________________________________________________________\n",
            "upsampling_193 (Upsampling)  multiple                  2294528   \n",
            "_________________________________________________________________\n",
            "upsampling_194 (Upsampling)  multiple                  573824    \n",
            "_________________________________________________________________\n",
            "upsampling_195 (Upsampling)  multiple                  144706    \n",
            "_________________________________________________________________\n",
            "conv2d_1322 (Conv2D)         multiple                  24        \n",
            "=================================================================\n",
            "Total params: 31,032,858\n",
            "Trainable params: 31,032,858\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hpK66uJKtMEh"
      },
      "source": [
        "#mask images\n",
        "import cv2\n",
        "import imutils\n",
        "\n",
        "cap = cv2.VideoCapture(input(\"Enter file name\"))\n",
        "ret, frame = cap.read()\n",
        "frameNo = 1\n",
        "\n",
        "outFileName = input(\"enter name.avi\")\n",
        "out = cv2.VideoWriter(outFileName,cv2.VideoWriter_fourcc('M','J','P','G'), 25, (IMG_WIDTH, IMG_HEIGHT))\n",
        "name = outFileName.split(\".\")[0]\n",
        "outArrow = cv2.VideoWriter(name+\"_arrow.avi\",cv2.VideoWriter_fourcc('M','J','P','G'), 25, (IMG_WIDTH, IMG_HEIGHT))\n",
        "\n",
        "leftCrop = 150\n",
        "rightCrop = 350\n",
        "rotateFrame = 270\n",
        "print(\"Rotating frame by \", rotateFrame, \" degrees\")\n",
        "print(\"Cropping frame from 0 to \", leftCrop, \" and \", rightCrop, \" to max y value\")\n",
        "\n",
        "ignoreHeightPixel = 10\n",
        "ignoreWidthPixel = 30\n",
        "print(\"Ignoring\", ignoreHeightPixel ,\" pixels from top and bottom\")\n",
        "print(\"Ignoring\", ignoreWidthPixel ,\" pixels from left and right\")\n",
        "\n",
        "while(1):\n",
        "    ret, frame = cap.read()\n",
        "    if ret == False :\n",
        "        print(\"Done\")\n",
        "        break\n",
        "\n",
        "\n",
        "    frame = imutils.rotate(frame, rotateFrame)\n",
        "    frame = frame[:,leftCrop:]\n",
        "    frame = frame[:, :rightCrop]\n",
        "    \n",
        "    origFrame = cv2.resize(frame, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_CUBIC)\n",
        "  \n",
        "    origFrameCopy = origFrame.copy()\n",
        "  \n",
        "  \n",
        "    frame = tf.image.convert_image_dtype(frame, tf.uint8)\n",
        "    frame = tf.image.resize(frame, (IMG_HEIGHT, IMG_WIDTH))\n",
        "    frame = tf.expand_dims(frame, 0)\n",
        "    frame = tf.cast(frame, tf.float32) / 255.0\n",
        " \n",
        "    prediction = model(frame)\n",
        "    prediction = tf.argmax(prediction, axis=-1)\n",
        "    prediction = tf.squeeze(prediction, axis = 0)\n",
        "    prediction = tf.expand_dims(prediction, axis=-1)\n",
        "    prediction = np.array(prediction)\n",
        "    prediction[prediction == 7] = 255\n",
        "    # get the mask and coord\n",
        "    xTot = 0\n",
        "    yTot = 0\n",
        "    Tot = 0\n",
        " \n",
        "    for i in range(origFrame.shape[0]) :\n",
        "        for j in range(origFrame.shape[1]) :\n",
        "            if prediction[i][j][0] == 0 or prediction[i][j][0] == 1 or prediction[i][j][0] == 2   :\n",
        "                origFrameCopy[i][j] = [0, 150 ,0]\n",
        "                if (i > ignoreHeightPixel and i < int(IMG_HEIGHT - ignoreHeightPixel)) and (j > ignoreWidthPixel and j <= int(IMG_WIDTH - ignoreWidthPixel)) :\n",
        "                    xTot += j\n",
        "                    yTot += i\n",
        "                    Tot += 1\n",
        "\n",
        "    alpha = 0.3\n",
        "    cv2.addWeighted(origFrameCopy, alpha, origFrame, 1 - alpha, 0, origFrame)\n",
        "    startpoint = (int(IMG_WIDTH/2), IMG_HEIGHT)\n",
        "    endpoint = (int(xTot/Tot), int(yTot/Tot))\n",
        "    out.write(origFrame)\n",
        "    outArrow.write(cv2.arrowedLine(origFrame, startpoint, endpoint, (255, 0, 0), 9, tipLength = 0.5))\n",
        "    frameNo += 1\n",
        "\n",
        "cap.release()\n",
        "out.release()\n",
        "outArrow.release()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}